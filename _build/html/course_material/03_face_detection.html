
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Face Detection &#8212; Computer Vision Course</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Smoothing and blurring" href="04_blur.html" />
    <link rel="prev" title="More on pixels" href="02_drawing.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo_com.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Computer Vision Course</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="01_introduction.html">
   Introduction to Computer vision
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="02_drawing.html">
   More on pixels
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Face Detection
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04_blur.html">
   Smoothing and blurring
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05_thres_edge_contour.html">
   Thresholding
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06_machine_learning.html">
   Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07_digit_recognition.html">
   Digit Recognition
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08_feature_extraction.html">
   Feature Extraction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09_ocr.html">
   Optical Character Recognition(OCR)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="10_conclusion.html">
   Conclusion
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#haar-cascade-classifiers">
   Haar Cascade Classifiers
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#real-time-face-detection">
   Real-time face detection
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#questionaire">
   Questionaire
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="face-detection">
<h1>Face Detection<a class="headerlink" href="#face-detection" title="Permalink to this headline">¶</a></h1>
<p>When you open camera app on your mobile phone to take someone’s photo, it automatically detects all the faces in the image and makes a yellow box around all the detected faces. Not just camera app, face detection is everywhere. Facebook automatically detects all the faces in the images and suggests your names while tagging.</p>
<p>As an exercise, try finding some more examples of face detection. You will be surprised.</p>
<div class="section" id="haar-cascade-classifiers">
<h2>Haar Cascade Classifiers<a class="headerlink" href="#haar-cascade-classifiers" title="Permalink to this headline">¶</a></h2>
<p>In order to build face recognition application, we will use the built-in Haar cascade classifiers in OpenCV. These classifiers have already been pre-trained to recognize faces!</p>
<p>Building our own classifier is certainly outside the scope of this case study. But if we wanted to, we would need a lot of “positive” and “negative” images. Positive images would contain images with faces, whereas negative images would contain images without faces. Based on this dataset, we could then extract features to characterize the face (or lack of face) in an image and build our own classifier. It would be a lot of work, and very time consuming. Things are even more difficult for someone, who is a computer vision novice. Luckily, OpenCV will do all the heavy lifting for us.</p>
<p><strong>Working</strong></p>
<p>Haar-Cascade classifiers work by scanning an image from left to right, and top to bottom, at varying scale sizes. Scanning an image from left to right and top to bottom is called the “sliding window” approach. As the window moves from left to right and top to bottom, one pixel at a time, the classifier is asked whether or not it “thinks” there is a face in the current window, based on the parameters that are supplied to the classifier.</p>
<p>Lets write some code …</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;../images/friends.jpeg&#39;</span><span class="p">)</span>
<span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;Image&#39;</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>I am a big fan of FRIENDS and hence big image, let’s resize it so that its much eaiser to visualize.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">w</span><span class="o">*</span><span class="mf">0.8</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">h</span><span class="o">*</span><span class="mf">0.8</span><span class="p">)))</span>
<span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;Image&#39;</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>much better now. We took the initial dimensions and then multiplied them with 0.8. The <code class="docutils literal notranslate"><span class="pre">cv2.resize</span></code> function take an image and the new dimensions i.e 80% of the previous width &amp; height.</p>
<p><strong>Note:</strong> We switched the order of <em>width</em> and <em>height</em>. Because when we say <code class="docutils literal notranslate"><span class="pre">img.shape</span></code> it returns the dimensions as per numpy cordinate system, but when we are using <code class="docutils literal notranslate"><span class="pre">cv2.resize</span></code> function, its expects the dimensions in opencv cordinate system.</p>
<p>Lets now save the resized image for future use.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cv2</span><span class="o">.</span><span class="n">imwrite</span><span class="p">(</span><span class="s1">&#39;images/friends2.jpeg&#39;</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>To detect faces in an image, we will have to convert the image into grayscale first. Infact, converting a color image to gray-scale is one of the most frequently used operation in computer vision. OpenCV has a handly little function for it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
<span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;Gray&#39;</span><span class="p">,</span> <span class="n">gray</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The first argument is always the image and second argument tells opencv about the current color space and the new color space to which the image is to be transformed.</p>
<p>You can use the same function to transform the image to other color spaces as well. By default, OpenCV uses BGR color space. To convert an image to RGB color space . .</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img_rgb</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
<span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;RGB&#39;</span><span class="p">,</span> <span class="n">img_rgb</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>to HSV color space …</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img_hsv</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2HSV</span><span class="p">)</span>
<span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;HSV&#39;</span><span class="p">,</span> <span class="n">img_hsv</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>You can read more about color spaces and their importances, <a class="reference external" href="https://www.dynamsoft.com/blog/insights/image-processing-101-color-models/">here</a>.</p>
<p>continuing with the problem in hand …
We have a black and white image now. Lets now talk about classifier.</p>
<p>Haar-Cascade classifiers are serialized as an XML file. You can easily load them using <code class="docutils literal notranslate"><span class="pre">cv2.CascadeClassifier()</span></code> method. This method take the path to the <em>xml</em> file as input and returns a classifier object.</p>
<p><strong>Note:</strong> You can find <em>xml</em> files for a lot of other classifier in the official git repo of opencv, <a class="reference external" href="https://github.com/opencv/opencv/tree/master/data/haarcascades">here</a></p>
<p>We have already download the <em>xml</em> file for detecting faces from the git repo. Its present inside data directory, lets try loading it</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">face_cascade</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CascadeClassifier</span><span class="p">(</span><span class="s1">&#39;data/face.xml&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Great, it ran without any error.</p>
<p>To detect actual faces in the image we make a call to the <code class="docutils literal notranslate"><span class="pre">detectMultiScale</span></code> method of our classifier. The method takes care of the entire face detection process. The method takes one required parameter, the image that he wants to find the faces in, followed by three optional arguments:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">scaleFactor</span></code>:  How much the image size is reduced. A value of 1.05 indicates that the image will by reduced by 5%</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">minNeighbors</span></code>:  How many neighbors each window should have for the area in the window to be considered a face. The cascade classifier will detect multiple windows around a face. This parameter controls how many rectangles (neighbors) need to be detected for the window to be labeled a face.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">minSize</span></code>:  A tuple of width and height (in pixels) indicating the minimum size of the window. Bounding boxes smaller than this size are ignored.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">faces</span> <span class="o">=</span> <span class="n">face_cascade</span><span class="o">.</span><span class="n">detectMultiScale</span><span class="p">(</span><span class="n">gray</span><span class="p">,</span> <span class="n">scaleFactor</span> <span class="o">=</span> <span class="mf">1.15</span><span class="p">,</span> <span class="n">minNeighbors</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">minSize</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">detectMultiScale</span></code> method then returns <em>a list of tuples containing the bounding boxes of the faces</em> in the image. These bounding boxes are simply the <em>(x, y)</em> location of the face, along with the <em>width</em> and <em>height</em> of the box.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">faces</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[272, 260,  91,  91],
       [590,  77,  98,  98],
       [734, 245, 102, 102],
       [638, 274, 106, 106],
       [503,  24,  94,  94],
       [389, 148,  96,  96]], dtype=int32)
</pre></div>
</div>
</div>
</div>
<p>our classifier has detected 6 faces in the image. We can draw one of them using <code class="docutils literal notranslate"><span class="pre">cv2.rectangle</span></code> function that we learned in the last notebook.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">faces</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">upper_left_corner</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">lower_right_corner</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">w</span><span class="p">,</span> <span class="n">y</span><span class="o">+</span><span class="n">h</span><span class="p">)</span>
<span class="n">color</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Lets draw our rectangle on the original image.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">upper_left_corner</span><span class="p">,</span> <span class="n">lower_right_corner</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;Image&#39;</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>so we have detected one face, now lets try to draw rectangles for all the faces that are detected</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">color</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="k">for</span> <span class="n">face</span> <span class="ow">in</span> <span class="n">faces</span><span class="p">:</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">face</span>
    <span class="n">upper_left_corner</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">lower_right_corner</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">w</span><span class="p">,</span> <span class="n">y</span><span class="o">+</span><span class="n">h</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">upper_left_corner</span><span class="p">,</span> <span class="n">lower_right_corner</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    
<span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;Image&#39;</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Amazing, we detected all the faces in the image. It looks a lot of code in the first go but actually its much simplier. I have written the complete code again, in a single cell. See if you can understand it now.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;images/friends2.jpeg&#39;</span><span class="p">)</span>
<span class="n">gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>

<span class="n">face_cascade</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CascadeClassifier</span><span class="p">(</span><span class="s1">&#39;data/face.xml&#39;</span><span class="p">)</span>
<span class="n">faces</span> <span class="o">=</span> <span class="n">face_cascade</span><span class="o">.</span><span class="n">detectMultiScale</span><span class="p">(</span><span class="n">gray</span><span class="p">,</span> <span class="n">scaleFactor</span> <span class="o">=</span> <span class="mf">1.15</span><span class="p">,</span> <span class="n">minNeighbors</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">minSize</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>

<span class="n">color</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="k">for</span> <span class="n">face</span> <span class="ow">in</span> <span class="n">faces</span><span class="p">:</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">face</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">w</span><span class="p">,</span> <span class="n">y</span><span class="o">+</span><span class="n">h</span><span class="p">),</span> <span class="n">color</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    
<span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;Image&#39;</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Its just ~10 lines of code. And the core logic is just ~3 lines. Sometimes, its really mind boggling how much you can achieve with just few lines of code.</p>
<p>It would be great to take this a step further and make it real time. We will take images from our webcam and detect faces, all in real-time.</p>
</div>
<div class="section" id="real-time-face-detection">
<h2>Real-time face detection<a class="headerlink" href="#real-time-face-detection" title="Permalink to this headline">¶</a></h2>
<p>First we need to access our webcam. With opencv, its just a function call.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">camera</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>argument <strong>0</strong> means read from built-in or USB webcam. You can read a video file from the disk by simply passing its path, instead of <strong>0</strong>.</p>
<p>Assuming that grabbing a reference to the video was successful, we can easily read the current frame by calling <code class="docutils literal notranslate"><span class="pre">read()</span></code> method of our <em>camera</em> object.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ret</span><span class="p">,</span> <span class="n">frame</span> <span class="o">=</span> <span class="n">camera</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">camera.read()</span></code> returns two values. The first value is a boolean, indicating whether the frame capture was successful or not. The second value is the actual frame/image captured. Lets display the image we have captured</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;Frame&#39;</span><span class="p">,</span> <span class="n">frame</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Once we know how to capture a single frame from the camera, we can easily loop over all frames in the video. At the most basic level, a video is simply a sequence of images put together, implying that we can read these frames one at a time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">ret</span><span class="p">,</span> <span class="n">img</span> <span class="o">=</span> <span class="n">camera</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;video&#39;</span><span class="p">,</span><span class="n">img</span><span class="p">)</span>

    <span class="n">k</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xff</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="nb">ord</span><span class="p">(</span><span class="s1">&#39;q&#39;</span><span class="p">):</span> <span class="c1"># press &#39;q&#39; to quit</span>
        <span class="k">break</span>
</pre></div>
</div>
</div>
</div>
<p>Whenever you write an infinite while loop, you have to implement the <em>break</em> condition. Here, the <em>break</em> condition looks a bit different. Lets break it down.</p>
<p><code class="docutils literal notranslate"><span class="pre">cv2.waitKey</span></code> waits for a key press. Its takes one optional argument, <em>delay</em> in milliseconds. 0 is the special value that means “forever”.
The function waitKey waits for a key event infinitely or for delay milliseconds, when it is positive. Here, we are using <code class="docutils literal notranslate"><span class="pre">cv2.waitKey(30)</span></code> it will display the frame for 30 ms, after which display will be automatically closed.</p>
<p>If in that 30 ms, you press any key then <code class="docutils literal notranslate"><span class="pre">cv2.waitKey</span></code> will return the interger corresponding to the key that was pressed. You can simply <em>&amp;</em> the returned value with <em>0xff</em>. <em>0xff</em> is a hexadecimal constant which is 11111111 in binary. By using bitwise AND (&amp;) with this constant, it leaves only the last 8 bits of the original (in this case, whatever cv2.waitKey(0) is).</p>
<p>Once you have the key value, you can check if it was <em>q</em> or not. If the key pressed was <em>q</em> then you can break the loop. The <code class="docutils literal notranslate"><span class="pre">ord()</span></code> function in Python accepts a character as an argument and returns the unicode code point representation of the passed argument. For example, in the above code, ord(‘q’) returns 113 which is a unicode code point value of character ‘q’.</p>
<p>It might look like a lot to remember and understand but, trust me, its very easy and you will get use to it pretty soon.</p>
<p>Final thing! In programming, whenever you access an I/O device like camera, USB, database and even files; you will have to close it explicitely when you are done using it. Here, we are capturing frames from our webcam. So, we will have to close it once we are done.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">camera</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Its a general practive to release the camera and then destroy all the windows. So, you will always see these commands used together.</p>
<p>Lets put everything back together. See if you understand it now</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">camera</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">ret</span><span class="p">,</span> <span class="n">img</span> <span class="o">=</span> <span class="n">camera</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">ret</span><span class="p">:</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;video&#39;</span><span class="p">,</span><span class="n">img</span><span class="p">)</span>

    <span class="n">k</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xff</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="nb">ord</span><span class="p">(</span><span class="s1">&#39;q&#39;</span><span class="p">):</span> <span class="c1"># press &#39;q&#39; to quit</span>
        <span class="k">break</span>
        
<span class="n">camera</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>This is all the code you need to read images from your webcam and display them. You can also save the images by calling <code class="docutils literal notranslate"><span class="pre">cv2.imwrite</span></code>.</p>
<p>We already know how to find faces in a single image. Since, inside the loop we have access to individual frames we easily use the same code from above the detect faces in each frame and then display them. Lets see it in action</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">color</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">face_cascade</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">CascadeClassifier</span><span class="p">(</span><span class="s1">&#39;data/face.xml&#39;</span><span class="p">)</span>
<span class="n">camera</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">ret</span><span class="p">,</span> <span class="n">img</span> <span class="o">=</span> <span class="n">camera</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">ret</span><span class="p">:</span>
        <span class="c1">## Code to detect faces</span>
        <span class="n">gray</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>        
        <span class="n">faces</span> <span class="o">=</span> <span class="n">face_cascade</span><span class="o">.</span><span class="n">detectMultiScale</span><span class="p">(</span><span class="n">gray</span><span class="p">,</span> <span class="n">scaleFactor</span> <span class="o">=</span> <span class="mf">1.15</span><span class="p">,</span> <span class="n">minNeighbors</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> <span class="n">minSize</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">face</span> <span class="ow">in</span> <span class="n">faces</span><span class="p">:</span>
            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="n">face</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">w</span><span class="p">,</span> <span class="n">y</span><span class="o">+</span><span class="n">h</span><span class="p">),</span> <span class="n">color</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;video&#39;</span><span class="p">,</span><span class="n">img</span><span class="p">)</span>

    <span class="n">k</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xff</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="nb">ord</span><span class="p">(</span><span class="s1">&#39;q&#39;</span><span class="p">):</span> <span class="c1"># press &#39;q&#39; to quit</span>
        <span class="k">break</span>
        
<span class="n">camera</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We won’t be explaining the code again, because there is nothing new. Spend a minute or two read the complete code. If you have any doubt you can ask your mentor.</p>
<p><strong>Note:</strong> One thing to notice here is, how easy it is to make a real-time application if you have the code to process an image. This is the case with all the computer vision applications that we build, we start with a single image and write all the code for it. Finally, to make it a real-time application, we simple grab the camera object and wrap an infinte while loop around it.</p>
<p>This is all the extra code you need to make something real-time in opencv</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">camera</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">ret</span><span class="p">,</span> <span class="n">img</span> <span class="o">=</span> <span class="n">camera</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">ret</span><span class="p">:</span>
        <span class="n">process_img</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="c1"># only this function is updated, depending upon the application</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s1">&#39;video&#39;</span><span class="p">,</span><span class="n">img</span><span class="p">)</span>

    <span class="n">k</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span> <span class="o">&amp;</span> <span class="mh">0xff</span>
    <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="nb">ord</span><span class="p">(</span><span class="s1">&#39;q&#39;</span><span class="p">):</span> <span class="c1"># press &#39;q&#39; to quit</span>
        <span class="k">break</span>
        
<span class="n">camera</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">destroyAllWindows</span><span class="p">()</span>

</pre></div>
</div>
<p>Its amazing, right?! Don’t worry if you did not understand everything now, we will be building many applications throughout the course. You will easily get accustom to it.</p>
</div>
<div class="section" id="questionaire">
<h2>Questionaire<a class="headerlink" href="#questionaire" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>How to resize images?</p></li>
<li><p>Name a few color spaces and also how to convert images from one color space to another?</p></li>
<li><p>What are haar cascade classifier and how they work?</p></li>
<li><p>How to read video input: webcam or mp4 from disk?</p></li>
<li><p>Difference between <code class="docutils literal notranslate"><span class="pre">cv2.waitkey(0)</span></code>, <code class="docutils literal notranslate"><span class="pre">cv2.waitkey(30)</span></code> and <code class="docutils literal notranslate"><span class="pre">cv2.waitkey(100)</span></code></p></li>
<li><p>Why is closing I/O devices important?</p></li>
<li><p>Which command is used to release camera?</p></li>
</ul>
<p>If you don’t know the answer to any of these question, then please read the notebook again or ask your mentor. There are some questions that your are suppose to google and read to know more.</p>
<p>In the next notebook, we will learn about image transformations like rotation, scaling, translation, etc.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./course_material"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="02_drawing.html" title="previous page">More on pixels</a>
    <a class='right-next' id="next-link" href="04_blur.html" title="next page">Smoothing and blurring</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By aiadventures<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>