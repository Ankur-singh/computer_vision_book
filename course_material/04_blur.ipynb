{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from utils import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing and blurring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We all know what blurring is. It’s what happens when your camera takes a picture out of focus. Sharper regions in the image lose their detail, normally as a disc or circular shape.\n",
    "\n",
    "Practically, this means that each pixel in the image is mixed in with its surrounding pixel intensities. This “mixture” of pixels in a neighborhood becomes our blurred pixel.\n",
    "\n",
    "While this effect is usually unwanted in our photographs, it’s actually quite helpful when performing image processing tasks. In fact, many image processing and computer vision functions, such as thresholding and edge detection, perform better if the image is first smoothed or blurred.\n",
    "\n",
    "**Note:** Sometimes the process is also called **filtering** because we use filters (i.e kernels) to smooth the image.\n",
    "\n",
    "There are many techniques of smoothing your images. Lets learn them one by one using *blurring.png* image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/blurring.png')\n",
    "imshow('Image', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to define a *k* x *k* sliding window or kernel, where *k* is always an **odd number**. We will then take the average of all the surrounding pixels in the *k* x *k* neighbour hood and assign it to the centre pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.blur(img, (7,7))\n",
    "imshow('Blurred Image', blurred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cv2.blur`, the first parameter is the source image on which were we have to apply average blurring, the second parameter is a tuple specifying the size of the kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian blurring is similar to average blurring, but instead of using a simple mean, we are now using a weighted mean, where neighborhood pixels that are closer to the central pixel contribute more “weight” to the average.\n",
    "\n",
    "The end result is that our image is more naturally blurred, than using the average method discussed previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.GaussianBlur(img, (11,11),0)\n",
    "imshow('Blurred Image', blurred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cv2.GaussianBlur`, to which we have provided three parameter first one being source image, second is the kernel size and the third is value of sigma in gaussian function (don't worry to much about it, just keep it 0). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median Blur is similar to average blur instead of taking average we are going to take median of every pixel in the filter and the value is going to be the value of center pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.medianBlur(img,5)\n",
    "imshow('Blurred Image', blurred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cv2.medianBlur`, the first parameter is source image and the second parameter is kernel size. With median blur we got really good result, it looks even better than the original image.\n",
    "\n",
    "**Note:** While other filters might be often useful, this method is highly effective in removing salt-and-pepper noise. A larger kernel size will use a larger matrix, and take pixels from further away from the center, which may or may not help. Whether you want a larger or smaller kernel really depends on the image, but 5 is a good number to start with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bilateral filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the above methods tend to blur edges. This is not the case for the bilateral filter, `cv2.bilateralFilter`, it is highly effective at noise removal while preserving edges. But the operation is slower compared to other filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.bilateralFilter(img, 9, 25, 25)\n",
    "imshow('Blurred Image', blurred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cv2.bilateralFilter`, the first parameter is source image, the second parameter is diameter of each pixel neighborhood. The next two arguments are for *filter sigma in the color space* and *filter sigma in the coordinate space*. You can read more about the arguments, [here](https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html?highlight=bilateralfilter#bilateralfilter). Still, the best way would be to try changing them and look at the output image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets compare the output of all these smoothing techniques, together! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_blur = cv2.blur(img, (7,7))\n",
    "cv2.imshow('Average Blur', avg_blur)\n",
    "\n",
    "gas_blur = cv2.GaussianBlur(img, (11,11),0)\n",
    "cv2.imshow('Gaussian Blur', gas_blur)\n",
    "\n",
    "med_blur = cv2.medianBlur(img,5)\n",
    "cv2.imshow('Median Blur', med_blur)\n",
    "\n",
    "bil_blur = cv2.bilateralFilter(img, 9, 25, 25)\n",
    "cv2.imshow('Bilateral Blur', bil_blur)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of smoothing technique is very application dependent. If preserving edges is important to you, then use bilateral filtering. If your image has salt-and-pepper noise then use median filtering. \n",
    "\n",
    "Generally speaking, gaussian filtering is a good starting point. Try playing with the kernel size until you get the desired results. Use other techniques only if you know what you are doing or the application demands it.\n",
    "\n",
    "**Key Takeaways**\n",
    "\n",
    "Applying a blur to an image smooths edges and removes noise from the image. Blurring is often used as a first step before we perform Thresholding, Edge Detection, or before we find the Contours of an image. Larger kernel size may remove more noise, but they will also remove detail from an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more smoothing techniques and algorithms in OpenCV, but we cannot learn about them all. Many of them are very application specific and you will hardly need them. \n",
    "\n",
    "**Note:** There are implementations for almost 2500 algorithms in OpenCV. Nobody can learn all of them. Also, nobody need all these algorithms together. So, when learning OpenCV, you should  focus on learning *how to use a particular function ?* and don't worry about the implementation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oil painting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One very interesting smoothing algorithm that makes your image look like its oil painted !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/friends2.jpeg')\n",
    "img = cv2.xphoto.oilPainting(img, 3, 1)\n",
    "imshow('Image', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing, right? OpenCV can make you an artist in real life. \n",
    "\n",
    "**Exercise:** \n",
    "- Try using a different image. Also, play with the values of the arguments to understand there impact better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Water color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You guessed it, this technique makes your image look like water colored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/friends2.jpeg')\n",
    "img = cv2.edgePreservingFilter(img, flags=1, sigma_s=160, sigma_r=0.7)\n",
    "imshow('Image', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are on a roll! Its time that you showcase your artistic skill to your friends, OpenCV got you covered.\n",
    "\n",
    "**Exercise:** \n",
    "- Try using a different image. Also, play with the values of *sigma_s* and *sigma_r* to understand them better. Don't change the value of *flags*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pencil Sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to make a pencil sketch from an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/friends2.jpeg')\n",
    "\n",
    "# pencil sketch code\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img_invert = cv2.bitwise_not(img_gray)\n",
    "img_smoothing = cv2.GaussianBlur(img_invert, (91, 91), sigmaX=0, sigmaY=0)\n",
    "final_img = cv2.divide(img_gray, 255 - img_smoothing, scale=256)\n",
    "\n",
    "imshow('Image', final_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a pencil sketch in less than a second, pretty dope! Lets try to understand it.\n",
    "\n",
    "- **Step - 1:** convert our image to gray-scale\n",
    "- **Step - 2:** invert the black and white colors in the gray-scale image from *step-1*\n",
    "- **Step - 3:** take the inverted image from *step-2* and apply gaussian blur to it\n",
    "- **Step - 4:** perform `(img_gray * 256)/(255 - img_smoothing)` using `cv2.divide`\n",
    "\n",
    "You already know `cv2.cvtColor` and `cv2.GaussianBlur` functions. There are only two new functions here: `cv2.divide` and `cv2.bitwise_not`. They are called *arithematic operations* and *bitwise operations* respectively. We will explore them next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithematic operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We all know basic arithmetic operations like addition and subtraction. But when working with images, we need to keep in mind the limits of our color space and data type.\n",
    "For example, RGB images have pixels that fall within the range [0, 255]. So what happens if we are examining a pixel with intensity 250 and we try to add 10 to it? Under normal arithmetic rules, we would end up with a value of 260. However, since RGB images are represented as 8-bit unsigned integers, 260 is not a valid value.\n",
    "\n",
    "So, what should happen? Should we perform a check of some sort to ensure no pixel falls outside the range of [0, 255], thus clipping all pixels to have a minimum value of\n",
    "0 and a maximum value of 255? Or do we apply a modulus operation, and “wrap around”? Under modulus rules, adding 10 to 250 would simply wrap around to a value of 4.\n",
    "\n",
    "Which way is the “correct” way to handle image additions and subtractions that fall outside the range of [0, 255]? The answer is there is no correct way – it simply depends on how you are manipulate your pixels and what you want the desired results to be. However, be sure to keep in mind that there is a difference between OpenCV and NumPy addition. NumPy will perform modulo arithmetic and “wrap around”. OpenCV, on the other hand, will perform clipping and ensure pixel values never fall outside the range [0, 255]. \n",
    "\n",
    "But don’t worry! These nuances will become clearer as we explore some code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones((5, 5, 3), dtype='uint8') * 100\n",
    "b = np.ones((5, 5, 3), dtype='uint8') * 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OpenCV arithematics\n",
    "max_cv = cv2.add(a, b)\n",
    "min_cv = cv2.subtract(a, b)\n",
    "\n",
    "max_cv.max(), min_cv.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 156)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy arithematics\n",
    "max_np = a + b\n",
    "min_np = a - b\n",
    "\n",
    "max_np.max(), min_np.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the difference we mentioned between OpenCV and NumPy addition above? Well, ponder for a minute to ensure you fully understand it.\n",
    "\n",
    "OpenCV takes care of clipping for us, and ensures that the arithematic operations produces a maximum value of *255* and a minimum value of *0*. On the other hand, NumPy does not perform clipping – it instead performs modulo arithmetic and “wraps around”. Once a value of 255 is reached, NumPy wraps around to zero, and then starts counting up again. And if it reaches 0, then it wraps around 255 and starts counting down.\n",
    "\n",
    "When performing integer arithmetic, it is important to keep in mind your desired output. Do you want all values to be clipped if they fall outside the range [0, 255]? Then use OpenCV’s built-in methods for image arithmetic.\n",
    "\n",
    "Do you want modulus arithmetic operations and have values wrap around if they fall outside the range of [0, 255]? Then simply add and subtract the NumPy arrays as you\n",
    "normally would.\n",
    "\n",
    "**Note:** For all arithematic operations between arrays, the input arrays *must have the same size*.\n",
    "\n",
    "Now that we have explored the caveats of image arithmetic in OpenCV and NumPy, let’s perform the arithmetic on actual images and view the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/friends2.jpeg')\n",
    "a = np.ones(img.shape, dtype='uint8') * 100\n",
    "\n",
    "added = cv2.add(img, a)\n",
    "cv2.imshow('Added', added)\n",
    "\n",
    "subtracted = cv2.subtract(img, a)\n",
    "cv2.imshow('Subtracted', subtracted)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have learned arithematic operation using OpenCV, now do you understand what this line of code is doing in the pencil sketch code:\n",
    "\n",
    "```python\n",
    "final_img = cv2.divide(img_gray, 255 - img_smoothing, scale=256)\n",
    "```\n",
    "\n",
    "It is simply taking two images (i.e. numpy array) and dividing them element-wise. After the division operation, we multiple the resultant array by 256 to bring everything back to [0-255] range. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we explored the peculiarities of image arithmetic using OpenCV and NumPy. These caveats are important to keep in mind, otherwise you may get unwanted results when performing arithmetic operations on your images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bitwise operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are very similar to AND, OR, XOR and NOT operations that we learned in our college. The best way to learn about bitwise operation is to use the classic example of square and circle mask.\n",
    "\n",
    "**Note:** if you don't remember the truth table for any operation then please refer the table below.\n",
    "\n",
    "\n",
    "| p | q | p AND q | p OR q | NOT p | p XOR q |\n",
    "|---|---|---------|--------|-------|---------|\n",
    "| T | T | T       | T      | F     | F       |\n",
    "| T | F | F       | T      | F     | T       |\n",
    "| F | T | F       | T      | T     | T       |\n",
    "| F | F | F       | F      | T     | F       |\n",
    "\n",
    "\n",
    "Lets write some code, shall we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_canvas = np.zeros((300, 300), dtype = \"uint8\")\n",
    "rectangle = cv2.rectangle(base_canvas, (25, 25), (275, 275), 255, -1)\n",
    "cv2.imshow(\"Rectangle\", rectangle)\n",
    "\n",
    "base_canvas = np.zeros((300, 300), dtype = \"uint8\")\n",
    "circle = cv2.circle(base_canvas, (150, 150), 150, 255, -1)\n",
    "cv2.imshow(\"Circle\", circle)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just created two images: one with a fill-in rectangle and other with a fill-in circle. \n",
    "\n",
    "In order to utilize bitwise functions, we assume (in most cases) that we are comparing two pixels (the only exception is the NOT function). Hence, its important that input images have same shape, else you will get an error complaining about it. We’ll compare each of the pixels and then construct our bitwise representation. \n",
    "\n",
    "Let’s quickly review our binary operations:\n",
    "- **AND:** A bitwise AND is true if and only if both pixels are greater than zero.\n",
    "- **OR:** A bitwise OR is true if either of the two pixels are greater than zero.\n",
    "- **XOR:** A bitwise XOR is true if and only if either of the two pixels are greater than zero, but not both.\n",
    "- **NOT:** A bitwise NOT inverts the “on” and “off” pixels in an image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_canvas = np.zeros((300, 300), dtype = \"uint8\")\n",
    "circle = cv2.circle(base_canvas, (150, 150), 150, 255, -1)\n",
    "\n",
    "base_canvas = np.zeros((300, 300), dtype = \"uint8\")\n",
    "rectangle = cv2.rectangle(base_canvas, (25, 25), (275, 275), 255, -1)\n",
    "\n",
    "bitwiseAnd = cv2.bitwise_and(rectangle, circle)\n",
    "cv2.imshow(\"AND\", bitwiseAnd)\n",
    "\n",
    "bitwiseOr = cv2.bitwise_or(rectangle, circle)\n",
    "cv2.imshow(\"OR\", bitwiseOr)\n",
    "\n",
    "bitwiseXor = cv2.bitwise_xor(rectangle, circle)\n",
    "cv2.imshow(\"XOR\", bitwiseXor)\n",
    "\n",
    "bitwiseNot = cv2.bitwise_not(rectangle)\n",
    "cv2.imshow(\"NOT\", bitwiseNot)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you see the output of each operation? Does it all make sense ? Spend a little time to collect your thoughts.\n",
    "\n",
    "Can you understand this line now?\n",
    "\n",
    "```python\n",
    "img_invert = cv2.bitwise_not(img_gray)\n",
    "```\n",
    "It simply invert our gray-scale image. We would really recommend you to visit the pencil sketch code again and see if you can understand it, now that you know ever function that is used.\n",
    "\n",
    "Overall, bitwise operations are extremely simple, yet very powerful. And they are absolutely essentially important in computer vision. But you will say, what are they useful for? Other than inverting gray-scale images, they are many other applications were bitwise operations are used. One such application is masking. We will learn about other applications later in the course. For now, lets talk about masking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking\n",
    "\n",
    "Using a mask allows us to focus only on the portions of the image that interests us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(img.shape[:2], dtype='uint8')\n",
    "mask = cv2.rectangle(mask, (222, 212), (378, 358), 255, -1)\n",
    "cv2.imshow(\"Mask\", mask)\n",
    "\n",
    "masked = cv2.bitwise_and(img, img, mask=mask)\n",
    "cv2.imshow(\"Masked\", masked)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct a NumPy array, filled with zeros, with the same width and height as our image. We then draw our white rectangle.\n",
    "\n",
    "We apply our mask using the `cv2.bitwise_and` function. The first two parameters are the image itself. Obviously, the AND function will be True for all pixels in the image; however, the important part of this function is the *mask* keyword argument. By supplying a mask, the `cv2.bitwise_and` function only examines pixels that are “on” in the mask. In this case, only pixels that are part of the white rectangle.\n",
    "\n",
    "**Exercise:** \n",
    "- Try making a circular mask around monica's face. You already know how to detect faces. Once you have the cordinates of the box, calculate the its center. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learned many new concepts in this notebook. The best way to make sure you understand all of them, is to make build some applications using them.\n",
    "\n",
    "**Excercise:**\n",
    "- Refer the previous notebook and try to develop a real-time sketch application. Its should take input images from the webcam and make sketch images in real-time. \n",
    "- Try to extend the real-time sketch app to generate oil painting and water color versions of videos from the webcam\n",
    "- Apply a circular mask to video feed from the webcam.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questionaire\n",
    "\n",
    "- Smoothing and blurring?\n",
    "- When to use median filtering?\n",
    "- When to use bilateral filtering?\n",
    "- Which one clips the values after 255, Numpy or OpenCV?\n",
    "- What will you get if you do `244 + 16`? First using numpy and then using OpenCV arithematics.\n",
    "- Bitwise AND, OR, XOR and NOT?\n",
    "- Masking ?\n",
    "\n",
    "In the next notebook, we will learn about thresholding and edge detection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
